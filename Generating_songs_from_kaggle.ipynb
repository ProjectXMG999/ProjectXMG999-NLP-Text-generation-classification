{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ProjectXMG999/ProjectXMG999-NLP-Text-generation-classification/blob/main/Generating_songs_from_kaggle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1wXWvOI-44k"
      },
      "source": [
        "# generating songs using RNNs (kaggle dataset)\n",
        "\n",
        "- 10k lines of lyrics( wont using full dataset couse of processing time)\n",
        "- predicting new wrod from a sequence\n",
        "- make the output a one-hot encoded label over entire corpus of desired text outputs\n",
        "- Using np.random.choice with the probabilities for more variance in predicted outputs\n",
        "- using only top-k most common words\n",
        "- tuning model\n",
        "- https://www.kaggle.com/datasets/deepshah16/song-lyrics-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEzHxczU-44r",
        "outputId": "bf3bf936-392f-42cc-df69-4fd1fc5323eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-03-09 20:10:57--  https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8\n",
            "Resolving drive.google.com (drive.google.com)... 209.85.146.113, 209.85.146.139, 209.85.146.102, ...\n",
            "Connecting to drive.google.com (drive.google.com)|209.85.146.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 303 See Other\n",
            "Location: https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/1men9hubr8e9svj3bpfg86ds4ri0744n/1678392600000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=bd35b210-dee4-4439-a908-3385a8fb5c81 [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2023-03-09 20:11:00--  https://doc-04-ak-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/1men9hubr8e9svj3bpfg86ds4ri0744n/1678392600000/11118900490791463723/*/1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8?uuid=bd35b210-dee4-4439-a908-3385a8fb5c81\n",
            "Resolving doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)... 64.233.191.132, 2607:f8b0:4001:c0c::84\n",
            "Connecting to doc-04-ak-docs.googleusercontent.com (doc-04-ak-docs.googleusercontent.com)|64.233.191.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 72436445 (69M) [text/csv]\n",
            "Saving to: ‘/tmp/songdata.csv’\n",
            "\n",
            "/tmp/songdata.csv   100%[===================>]  69.08M  54.0MB/s    in 1.3s    \n",
            "\n",
            "2023-03-09 20:11:01 (54.0 MB/s) - ‘/tmp/songdata.csv’ saved [72436445/72436445]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.utils import pad_sequences\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://drive.google.com/uc?id=1LiJFZd41ofrWoBtW-pMYsfz1w8Ny0Bj8 \\\n",
        "    -O /tmp/songdata.csv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOT305Xt-44t",
        "outputId": "b5cec073-8274-43f0-ee65-3ec77efa8dae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-a08e8deff054>:14: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
            "<ipython-input-2-a08e8deff054>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n"
          ]
        }
      ],
      "source": [
        "# Preprocessing\n",
        "\n",
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "def create_lyrics_corpus(dataset, field):\n",
        "  # Remove all other punctuation\n",
        "  dataset[field] = dataset[field].str.replace('[{}]'.format(string.punctuation), '')\n",
        "  # Make it lowercase\n",
        "  dataset[field] = dataset[field].str.lower()\n",
        "  # Make it one long string to split by line\n",
        "  lyrics = dataset[field].str.cat()\n",
        "  corpus = lyrics.split('\\n')\n",
        "  # Remove any trailing whitespace\n",
        "  for l in range(len(corpus)):\n",
        "    corpus[l] = corpus[l].rstrip()\n",
        "  # Remove any empty lines\n",
        "  corpus = [l for l in corpus if l != '']\n",
        "\n",
        "  return corpus\n",
        "\n",
        "\n",
        "def tokenize_corpus(corpus, num_words=-1):\n",
        "  # Fit a Tokenizer on the corpus\n",
        "  if num_words > -1:\n",
        "    tokenizer = Tokenizer(num_words=num_words)\n",
        "  else:\n",
        "    tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(corpus)\n",
        "  return tokenizer\n",
        "\n",
        "# Read the dataset from csv - this time with 250 songs\n",
        "dataset = pd.read_csv('/tmp/songdata.csv', dtype=str)[:250]\n",
        "# Create the corpus using the 'text' column containing lyrics\n",
        "corpus = create_lyrics_corpus(dataset, 'text')\n",
        "# Tokenize the corpus\n",
        "tokenizer = tokenize_corpus(corpus, num_words=2000)\n",
        "total_words = tokenizer.num_words\n",
        "\n",
        "# There should be a lot more words now\n",
        "print(total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2oyBN3-T-44v"
      },
      "outputs": [],
      "source": [
        "# creating sequences and labels\n",
        "\n",
        "sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tsequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences for equal input length \n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = np.array(pad_sequences(sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# Split sequences between the \"input\" sequence and \"output\" predicted word\n",
        "input_sequences, labels = sequences[:,:-1], sequences[:,-1]\n",
        "# One-hot encode the labels\n",
        "one_hot_labels = tf.keras.utils.to_categorical(labels, num_classes=total_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVLtoLM9-44w",
        "outputId": "46d8770d-08e7-4692-fa96-012a3abe1b6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1480/1480 [==============================] - 30s 14ms/step - loss: 5.9842 - accuracy: 0.0462\n",
            "Epoch 2/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 5.7069 - accuracy: 0.0501\n",
            "Epoch 3/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 5.5156 - accuracy: 0.0635\n",
            "Epoch 4/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 5.3027 - accuracy: 0.0968\n",
            "Epoch 5/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 5.1410 - accuracy: 0.1161\n",
            "Epoch 6/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 5.0007 - accuracy: 0.1301\n",
            "Epoch 7/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.8726 - accuracy: 0.1404\n",
            "Epoch 8/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.7569 - accuracy: 0.1511\n",
            "Epoch 9/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.6443 - accuracy: 0.1623\n",
            "Epoch 10/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 4.5442 - accuracy: 0.1737\n",
            "Epoch 11/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.4552 - accuracy: 0.1810\n",
            "Epoch 12/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.3738 - accuracy: 0.1896\n",
            "Epoch 13/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.2988 - accuracy: 0.1983\n",
            "Epoch 14/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.2304 - accuracy: 0.2057\n",
            "Epoch 15/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.1666 - accuracy: 0.2137\n",
            "Epoch 16/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 4.1089 - accuracy: 0.2214\n",
            "Epoch 17/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 4.0475 - accuracy: 0.2277\n",
            "Epoch 18/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.9777 - accuracy: 0.2369\n",
            "Epoch 19/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 3.8987 - accuracy: 0.2481\n",
            "Epoch 20/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.8236 - accuracy: 0.2607\n",
            "Epoch 21/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.7538 - accuracy: 0.2692\n",
            "Epoch 22/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.6887 - accuracy: 0.2780\n",
            "Epoch 23/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 3.6299 - accuracy: 0.2858\n",
            "Epoch 24/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.5773 - accuracy: 0.2938\n",
            "Epoch 25/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.5270 - accuracy: 0.3033\n",
            "Epoch 26/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.4817 - accuracy: 0.3065\n",
            "Epoch 27/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.4389 - accuracy: 0.3152\n",
            "Epoch 28/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.3954 - accuracy: 0.3218\n",
            "Epoch 29/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.3586 - accuracy: 0.3254\n",
            "Epoch 30/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.3215 - accuracy: 0.3325\n",
            "Epoch 31/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.2888 - accuracy: 0.3361\n",
            "Epoch 32/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 3.2545 - accuracy: 0.3420\n",
            "Epoch 33/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.2258 - accuracy: 0.3465\n",
            "Epoch 34/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.1957 - accuracy: 0.3507\n",
            "Epoch 35/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.1656 - accuracy: 0.3549\n",
            "Epoch 36/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.1382 - accuracy: 0.3605\n",
            "Epoch 37/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.1141 - accuracy: 0.3639\n",
            "Epoch 38/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.0874 - accuracy: 0.3700\n",
            "Epoch 39/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.0640 - accuracy: 0.3725\n",
            "Epoch 40/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 3.0405 - accuracy: 0.3755\n",
            "Epoch 41/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 3.0165 - accuracy: 0.3795\n",
            "Epoch 42/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9982 - accuracy: 0.3839\n",
            "Epoch 43/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9770 - accuracy: 0.3873\n",
            "Epoch 44/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9606 - accuracy: 0.3884\n",
            "Epoch 45/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9406 - accuracy: 0.3915\n",
            "Epoch 46/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9210 - accuracy: 0.3958\n",
            "Epoch 47/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.9064 - accuracy: 0.3998\n",
            "Epoch 48/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8876 - accuracy: 0.4014\n",
            "Epoch 49/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8690 - accuracy: 0.4053\n",
            "Epoch 50/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 2.8579 - accuracy: 0.4046\n",
            "Epoch 51/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8363 - accuracy: 0.4110\n",
            "Epoch 52/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8206 - accuracy: 0.4118\n",
            "Epoch 53/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.8066 - accuracy: 0.4138\n",
            "Epoch 54/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7884 - accuracy: 0.4183\n",
            "Epoch 55/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7754 - accuracy: 0.4203\n",
            "Epoch 56/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7641 - accuracy: 0.4213\n",
            "Epoch 57/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7499 - accuracy: 0.4256\n",
            "Epoch 58/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7367 - accuracy: 0.4288\n",
            "Epoch 59/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.7184 - accuracy: 0.4314\n",
            "Epoch 60/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.7082 - accuracy: 0.4324\n",
            "Epoch 61/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6950 - accuracy: 0.4355\n",
            "Epoch 62/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6879 - accuracy: 0.4349\n",
            "Epoch 63/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.6688 - accuracy: 0.4406\n",
            "Epoch 64/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.6565 - accuracy: 0.4414\n",
            "Epoch 65/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6444 - accuracy: 0.4431\n",
            "Epoch 66/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6351 - accuracy: 0.4465\n",
            "Epoch 67/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.6190 - accuracy: 0.4486\n",
            "Epoch 68/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 2.6130 - accuracy: 0.4494\n",
            "Epoch 69/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5972 - accuracy: 0.4523\n",
            "Epoch 70/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5884 - accuracy: 0.4525\n",
            "Epoch 71/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5764 - accuracy: 0.4572\n",
            "Epoch 72/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5659 - accuracy: 0.4565\n",
            "Epoch 73/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5633 - accuracy: 0.4589\n",
            "Epoch 74/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5416 - accuracy: 0.4601\n",
            "Epoch 75/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5406 - accuracy: 0.4626\n",
            "Epoch 76/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 2.5268 - accuracy: 0.4642\n",
            "Epoch 77/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.5146 - accuracy: 0.4658\n",
            "Epoch 78/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.5100 - accuracy: 0.4682\n",
            "Epoch 79/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4999 - accuracy: 0.4689\n",
            "Epoch 80/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4893 - accuracy: 0.4717\n",
            "Epoch 81/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4788 - accuracy: 0.4726\n",
            "Epoch 82/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4743 - accuracy: 0.4747\n",
            "Epoch 83/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4587 - accuracy: 0.4766\n",
            "Epoch 84/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4543 - accuracy: 0.4779\n",
            "Epoch 85/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4549 - accuracy: 0.4772\n",
            "Epoch 86/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4351 - accuracy: 0.4795\n",
            "Epoch 87/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4357 - accuracy: 0.4809\n",
            "Epoch 88/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4201 - accuracy: 0.4840\n",
            "Epoch 89/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4133 - accuracy: 0.4850\n",
            "Epoch 90/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.4205 - accuracy: 0.4830\n",
            "Epoch 91/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3940 - accuracy: 0.4880\n",
            "Epoch 92/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3912 - accuracy: 0.4881\n",
            "Epoch 93/100\n",
            "1480/1480 [==============================] - 11s 8ms/step - loss: 2.3779 - accuracy: 0.4909\n",
            "Epoch 94/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3780 - accuracy: 0.4905\n",
            "Epoch 95/100\n",
            "1480/1480 [==============================] - 10s 7ms/step - loss: 2.3781 - accuracy: 0.4900\n",
            "Epoch 96/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3577 - accuracy: 0.4935\n",
            "Epoch 97/100\n",
            "1480/1480 [==============================] - 12s 8ms/step - loss: 2.3648 - accuracy: 0.4935\n",
            "Epoch 98/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3488 - accuracy: 0.4948\n",
            "Epoch 99/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3318 - accuracy: 0.4994\n",
            "Epoch 100/100\n",
            "1480/1480 [==============================] - 11s 7ms/step - loss: 2.3366 - accuracy: 0.4986\n"
          ]
        }
      ],
      "source": [
        "# training tex generation model\n",
        "\n",
        "#  cutting of after 100 epochs ( no time for that)\n",
        "\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 64, input_length=max_sequence_len-1))\n",
        "model.add(Bidirectional(LSTM(20)))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(input_sequences, one_hot_labels, epochs=100, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "bS79KnGB-44x",
        "outputId": "9e8bdfcb-8a36-4255-8513-c769a417cf2e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Visualization\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_graphs(history, string):\n",
        "  plt.plot(history.history[string])\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(string)\n",
        "  plt.show()\n",
        "\n",
        "plot_graphs(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niqyCLvw-44x",
        "outputId": "251b906b-1f38-4142-96d3-96a43e2c1e51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 85ms/step\n",
            "1/1 [==============================] - 0s 89ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "im feeling chills me to me tonight and now youre so hard when you please think of me and bobby and bobbys brother the bone day tune hell wed good more to joy door intrusion mess girls mama love tramp kids throat images chasing flash bother share share world beg choice share share share share explain complain knees beams misery crowd trooper trooper lousy lesson outward world given john mm john resist chasing feather feather movie movie wonderful great gritty chasing bird wall bang head like paint close close mighty above couldnt roxy thats me best shut couldnt tell me i have to\n"
          ]
        }
      ],
      "source": [
        "# generating time\n",
        "\n",
        "\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "\ttoken_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "\ttoken_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "\tpredicted = np.argmax(model.predict(token_list), axis=-1)\n",
        "\toutput_word = \"\"\n",
        "\tfor word, index in tokenizer.word_index.items():\n",
        "\t\tif index == predicted:\n",
        "\t\t\toutput_word = word\n",
        "\t\t\tbreak\n",
        "\tseed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQuNN74N-44y",
        "outputId": "85e38e50-1cf6-4730-91f6-7eedf85e0704"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "7\n"
          ]
        }
      ],
      "source": [
        "# Test the method with just the first word after the seed text\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "predicted_probs = model.predict(token_list)[0]\n",
        "predicted = np.random.choice([x for x in range(len(predicted_probs))], \n",
        "                             p=predicted_probs)\n",
        "# Running this cell multiple times should get you some variance in output\n",
        "print(predicted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP5jcsyq-44z",
        "outputId": "e6804a63-e643-4277-e0bd-834aa8b83ead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "im feeling chills it all youre at my sense dont i have come and cry now youre headin down tonight close your shoes from short me like a blues through laugh jeanie than breaking place around where spin by fall shut harm me out me things think that i bring on you twice stops you shines you better life use man is a fool into deep over faces baby break ya things conceal chat choice no goin choice choice choice choice choice choice choice harm beg thrill rather this things beg harm remember shine talking call nothings bittersweet go losin write of certain\n"
          ]
        }
      ],
      "source": [
        "# Use this process for the full output generation\n",
        "seed_text = \"im feeling chills\"\n",
        "next_words = 100\n",
        "  \n",
        "for _ in range(next_words):\n",
        "  token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "  token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "  predicted_probs = model.predict(token_list)[0]\n",
        "  predicted = np.random.choice([x for x in range(len(predicted_probs))],\n",
        "                               p=predicted_probs)\n",
        "  output_word = \"\"\n",
        "  for word, index in tokenizer.word_index.items():\n",
        "    if index == predicted:\n",
        "      output_word = word\n",
        "      break\n",
        "  seed_text += \" \" + output_word\n",
        "print(seed_text)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}