{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Just a training code/ Theoretical knowledge of Markov Models\n",
    "- Training separate models for each class\n",
    "- using Bayes Rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-03-07 16:57:21--  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 26622 (26K) [text/plain]\n",
      "Saving to: ‘edgar_allan_poe.txt’\n",
      "\n",
      "edgar_allan_poe.txt 100%[===================>]  26,00K  --.-KB/s    in 0,006s  \n",
      "\n",
      "2023-03-07 16:57:21 (4,16 MB/s) - ‘edgar_allan_poe.txt’ saved [26622/26622]\n",
      "\n",
      "--2023-03-07 16:57:21--  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 56286 (55K) [text/plain]\n",
      "Saving to: ‘robert_frost.txt’\n",
      "\n",
      "robert_frost.txt    100%[===================>]  54,97K  --.-KB/s    in 0,02s   \n",
      "\n",
      "2023-03-07 16:57:22 (2,79 MB/s) - ‘robert_frost.txt’ saved [56286/56286]\n",
      "\n",
      "LO! Death hath rear'd himself a throne\n",
      "In a strange city, all alone,\n",
      "Far down within the dim west\n",
      "Where the good, and the bad, and the worst, and the best,\n",
      "Have gone to their eternal rest.\n",
      " \n",
      "There shrines, and palaces, and towers\n",
      "Are not like any thing of ours\n",
      "Oh no! O no! ours never loom\n",
      "To heaven with that ungodly gloom!\n"
     ]
    }
   ],
   "source": [
    "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/edgar_allan_poe.txt\n",
    "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "\n",
    "input_files = [\n",
    "  'edgar_allan_poe.txt',\n",
    "  'robert_frost.txt',\n",
    "]\n",
    "\n",
    "!head edgar_allan_poe.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two roads diverged in a yellow wood,\n",
      "And sorry I could not travel both\n",
      "And be one traveler, long I stood\n",
      "And looked down one as far as I could\n",
      "To where it bent in the undergrowth; \n",
      "\n",
      "Then took the other, as just as fair,\n",
      "And having perhaps the better claim\n",
      "Because it was grassy and wanted wear,\n",
      "Though as for that the passing there\n"
     ]
    }
   ],
   "source": [
    "!head robert_frost.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edgar_allan_poe.txt corresponds to label 0\n",
      "robert_frost.txt corresponds to label 1\n"
     ]
    }
   ],
   "source": [
    "# collect data into lists\n",
    "input_texts = []\n",
    "labels = []\n",
    "\n",
    "for label, f in enumerate(input_files):\n",
    "  print(f\"{f} corresponds to label {label}\")\n",
    "\n",
    "  for line in open(f):\n",
    "    line = line.rstrip().lower()\n",
    "    if line:\n",
    "      # remove punctuation\n",
    "      line = line.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "      input_texts.append(line)\n",
    "      labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, test_text, Ytrain, Ytest = train_test_split(input_texts, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1615, 539)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Ytrain), len(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the truest the most fervently devoted',\n",
       " 'and fight in a smother',\n",
       " 'of what in other worlds shall be and given',\n",
       " 'come up in despite of the lion',\n",
       " 'sitting or standing as he chose']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ytrain[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "word2idx = {'<unk>': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populate word2idx\n",
    "for text in train_text:\n",
    "    tokens = text.split()\n",
    "    for token in tokens:\n",
    "      if token not in word2idx:\n",
    "        word2idx[token] = idx\n",
    "        idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<unk>': 0,\n",
       " 'the': 1,\n",
       " 'truest': 2,\n",
       " 'most': 3,\n",
       " 'fervently': 4,\n",
       " 'devoted': 5,\n",
       " 'and': 6,\n",
       " 'fight': 7,\n",
       " 'in': 8,\n",
       " 'a': 9,\n",
       " 'smother': 10,\n",
       " 'of': 11,\n",
       " 'what': 12,\n",
       " 'other': 13,\n",
       " 'worlds': 14,\n",
       " 'shall': 15,\n",
       " 'be': 16,\n",
       " 'given': 17,\n",
       " 'come': 18,\n",
       " 'up': 19,\n",
       " 'despite': 20,\n",
       " 'lion': 21,\n",
       " 'sitting': 22,\n",
       " 'or': 23,\n",
       " 'standing': 24,\n",
       " 'as': 25,\n",
       " 'he': 26,\n",
       " 'chose': 27,\n",
       " 'all': 28,\n",
       " 'we': 29,\n",
       " 'can': 30,\n",
       " 'hold': 31,\n",
       " 'together': 32,\n",
       " 'by': 33,\n",
       " 'legs': 34,\n",
       " 'thee': 35,\n",
       " 'poetry': 36,\n",
       " 'thy': 37,\n",
       " 'presence': 38,\n",
       " 'leaves': 39,\n",
       " 'that': 40,\n",
       " 'were': 41,\n",
       " 'crisped': 42,\n",
       " 'sere': 43,\n",
       " 'town': 44,\n",
       " 'is': 45,\n",
       " 'no': 46,\n",
       " 'more': 47,\n",
       " 'from': 48,\n",
       " 'sun': 49,\n",
       " 'stars': 50,\n",
       " 'whence': 51,\n",
       " 'had': 52,\n",
       " 'drawn': 53,\n",
       " 'forth': 54,\n",
       " 'those': 55,\n",
       " 'name': 56,\n",
       " 'stark': 57,\n",
       " 'gathered': 58,\n",
       " 'bow': 59,\n",
       " 'i': 60,\n",
       " 'paused': 61,\n",
       " 'rested': 62,\n",
       " 'on': 63,\n",
       " 'sort': 64,\n",
       " 'hook': 65,\n",
       " 'could': 66,\n",
       " 'see': 67,\n",
       " 'nothing': 68,\n",
       " 'toffile': 69,\n",
       " 'dont': 70,\n",
       " 'it': 71,\n",
       " 'so': 72,\n",
       " 'now': 73,\n",
       " 'theyve': 74,\n",
       " 'dragged': 75,\n",
       " 'through': 76,\n",
       " 'law': 77,\n",
       " 'courts': 78,\n",
       " 'once': 79,\n",
       " 'sorry': 80,\n",
       " 'not': 81,\n",
       " 'travel': 82,\n",
       " 'both': 83,\n",
       " 'blame': 84,\n",
       " 'his': 85,\n",
       " 'being': 86,\n",
       " 'brought': 87,\n",
       " 'mother': 88,\n",
       " 'wasted': 89,\n",
       " 'like': 90,\n",
       " 'snow': 91,\n",
       " 'will': 92,\n",
       " 'start': 93,\n",
       " 'which': 94,\n",
       " 'lately': 95,\n",
       " 'slept': 96,\n",
       " 'apathy': 97,\n",
       " 'terror': 98,\n",
       " 'she': 99,\n",
       " 'spoke': 100,\n",
       " 'letting': 101,\n",
       " 'sink': 102,\n",
       " 'her': 103,\n",
       " 'newcut': 104,\n",
       " 'narrow': 105,\n",
       " 'gap': 106,\n",
       " 'flattered': 107,\n",
       " 'must': 108,\n",
       " 'to': 109,\n",
       " 'have': 110,\n",
       " 'two': 111,\n",
       " 'towns': 112,\n",
       " 'fighting': 113,\n",
       " 'brown': 114,\n",
       " 'lived': 115,\n",
       " 'at': 116,\n",
       " 'such': 117,\n",
       " 'lofty': 118,\n",
       " 'farm': 119,\n",
       " 'cannot': 120,\n",
       " 'lady': 121,\n",
       " 'alone': 122,\n",
       " 'perhaps': 123,\n",
       " 'you': 124,\n",
       " 'art': 125,\n",
       " 'mean': 126,\n",
       " 'than': 127,\n",
       " 'even': 128,\n",
       " 'seraph': 129,\n",
       " 'harper': 130,\n",
       " 'israfel': 131,\n",
       " 'with': 132,\n",
       " 'love': 133,\n",
       " 'luminous': 134,\n",
       " 'eyes': 135,\n",
       " 'virgin': 136,\n",
       " 'wrapper': 137,\n",
       " 'deep': 138,\n",
       " 'box': 139,\n",
       " 'stumps': 140,\n",
       " 'still': 141,\n",
       " 'bleeding': 142,\n",
       " 'their': 143,\n",
       " 'life': 144,\n",
       " 'away': 145,\n",
       " 'was': 146,\n",
       " 'some': 147,\n",
       " 'money': 148,\n",
       " 'suddenly': 149,\n",
       " 'into': 150,\n",
       " 'ive': 151,\n",
       " 'been': 152,\n",
       " 'built': 153,\n",
       " 'here': 154,\n",
       " 'big': 155,\n",
       " 'church': 156,\n",
       " 'organ': 157,\n",
       " 'begin': 158,\n",
       " 'over': 159,\n",
       " 'there': 160,\n",
       " 'shed': 161,\n",
       " 'better': 162,\n",
       " 'stop': 163,\n",
       " 'revels': 164,\n",
       " 'region': 165,\n",
       " 'sighs': 166,\n",
       " 'under': 167,\n",
       " 'man': 168,\n",
       " 'wife': 169,\n",
       " 'oh': 170,\n",
       " 'kept': 171,\n",
       " 'first': 172,\n",
       " 'for': 173,\n",
       " 'another': 174,\n",
       " 'day': 175,\n",
       " 'trapper': 176,\n",
       " 'looking': 177,\n",
       " 'door': 178,\n",
       " 'never': 179,\n",
       " 'takes': 180,\n",
       " 'if': 181,\n",
       " 'theyre': 182,\n",
       " 'worth': 183,\n",
       " 'moon': 184,\n",
       " 'saw': 185,\n",
       " 'before': 186,\n",
       " 'they': 187,\n",
       " 'clock': 188,\n",
       " 'where': 189,\n",
       " 'trees': 190,\n",
       " 'grow': 191,\n",
       " 'short': 192,\n",
       " 'mosses': 193,\n",
       " 'tall': 194,\n",
       " 'awake': 195,\n",
       " 'us': 196,\n",
       " 'tis': 197,\n",
       " 'symbol': 198,\n",
       " 'token': 199,\n",
       " 'watched': 200,\n",
       " 'forty': 201,\n",
       " 'cellar': 202,\n",
       " 'holes': 203,\n",
       " 'who': 204,\n",
       " 'favor': 205,\n",
       " 'fire': 206,\n",
       " 'withering': 207,\n",
       " 'couldnt': 208,\n",
       " 'call': 209,\n",
       " 'living': 210,\n",
       " 'aint': 211,\n",
       " 'winter': 212,\n",
       " 'after': 213,\n",
       " 'halfpast': 214,\n",
       " 'three': 215,\n",
       " 'took': 216,\n",
       " 'one': 217,\n",
       " 'less': 218,\n",
       " 'traveled': 219,\n",
       " 'tho': 220,\n",
       " 'faith': 221,\n",
       " 'godliness': 222,\n",
       " 'whose': 223,\n",
       " 'throne': 224,\n",
       " 'smell': 225,\n",
       " 'drowned': 226,\n",
       " 'rain': 227,\n",
       " 'made': 228,\n",
       " 'him': 229,\n",
       " 'gather': 230,\n",
       " 'me': 231,\n",
       " 'wet': 232,\n",
       " 'berries': 233,\n",
       " 'wouldnt': 234,\n",
       " 'hurt': 235,\n",
       " 'hen': 236,\n",
       " 'ought': 237,\n",
       " 'yes': 238,\n",
       " 'heaven': 239,\n",
       " 'thine': 240,\n",
       " 'but': 241,\n",
       " 'this': 242,\n",
       " 'legended': 243,\n",
       " 'tomb': 244,\n",
       " 'said': 245,\n",
       " 'written': 246,\n",
       " 'sweet': 247,\n",
       " 'sister': 248,\n",
       " 'woods': 249,\n",
       " 'winds': 250,\n",
       " 'mountains': 251,\n",
       " 'intense': 252,\n",
       " 'only': 253,\n",
       " 'adding': 254,\n",
       " 'frost': 255,\n",
       " 'john': 256,\n",
       " 'threw': 257,\n",
       " 'wide': 258,\n",
       " 'didnt': 259,\n",
       " 'enter': 260,\n",
       " 'checked': 261,\n",
       " 'pace': 262,\n",
       " 'sacred': 263,\n",
       " 'weeping': 264,\n",
       " 'bless': 265,\n",
       " 'blow': 266,\n",
       " 'open': 267,\n",
       " 'grassy': 268,\n",
       " 'places': 269,\n",
       " 'bleak': 270,\n",
       " 'sought': 271,\n",
       " 'precipitate': 272,\n",
       " 'pathway': 273,\n",
       " 'lie': 274,\n",
       " 'dead': 275,\n",
       " 'my': 276,\n",
       " 'heartstrings': 277,\n",
       " 'why': 278,\n",
       " 'should': 279,\n",
       " 'bear': 280,\n",
       " 'furthest': 281,\n",
       " 'bodies': 282,\n",
       " 'gailyjewelld': 283,\n",
       " 'wave': 284,\n",
       " 'ripple': 285,\n",
       " 'himself': 286,\n",
       " 'wont': 287,\n",
       " 'imagine': 288,\n",
       " 'want': 289,\n",
       " 'fountain': 290,\n",
       " 'scarce': 291,\n",
       " 'know': 292,\n",
       " 'prize': 293,\n",
       " 'high': 294,\n",
       " 'thats': 295,\n",
       " 'smart': 296,\n",
       " 'pair': 297,\n",
       " 'pumps': 298,\n",
       " 'youre': 299,\n",
       " 'beading': 300,\n",
       " 'think': 301,\n",
       " 'too': 302,\n",
       " 'much': 303,\n",
       " 'having': 304,\n",
       " 'shaded': 305,\n",
       " 'out': 306,\n",
       " 'wanted': 307,\n",
       " 'take': 308,\n",
       " 'houri': 309,\n",
       " 'glances': 310,\n",
       " 'are': 311,\n",
       " 'israfeli': 312,\n",
       " 'despisest': 313,\n",
       " 'let': 314,\n",
       " 'tremulous': 315,\n",
       " 'light': 316,\n",
       " 'prospect': 317,\n",
       " 'terminates': 318,\n",
       " 'kitchen': 319,\n",
       " 'bedroom': 320,\n",
       " 'wantonest': 321,\n",
       " 'singing': 322,\n",
       " 'birds': 323,\n",
       " 'would': 324,\n",
       " 'go': 325,\n",
       " 'yet': 326,\n",
       " 'gone': 327,\n",
       " 'sit': 328,\n",
       " 'tell': 329,\n",
       " 'everything': 330,\n",
       " 'ah': 331,\n",
       " 'night': 332,\n",
       " 'nights': 333,\n",
       " 'year': 334,\n",
       " 'nowhere': 335,\n",
       " 'tower': 336,\n",
       " 'little': 337,\n",
       " 'silver': 338,\n",
       " 'bells': 339,\n",
       " 'send': 340,\n",
       " 'sailing': 341,\n",
       " 'attic': 342,\n",
       " 'window': 343,\n",
       " 'bade': 344,\n",
       " 'pause': 345,\n",
       " 'gardengate': 346,\n",
       " 'make': 347,\n",
       " 'yourself': 348,\n",
       " 'cheering': 349,\n",
       " 'song': 350,\n",
       " 'how': 351,\n",
       " 'back': 352,\n",
       " 'say': 353,\n",
       " 'goodbye': 354,\n",
       " 'since': 355,\n",
       " 'began': 356,\n",
       " 'its': 357,\n",
       " 'important': 358,\n",
       " 'though': 359,\n",
       " 'isnt': 360,\n",
       " 'men': 361,\n",
       " 'ridiculous': 362,\n",
       " 'hoary': 363,\n",
       " 'groans': 364,\n",
       " 'woe': 365,\n",
       " 'wherever': 366,\n",
       " 'ground': 367,\n",
       " 'low': 368,\n",
       " 'fifteen': 369,\n",
       " 'time': 370,\n",
       " 'tended': 371,\n",
       " 'anything': 372,\n",
       " 'herself': 373,\n",
       " 'sell': 374,\n",
       " 'keep': 375,\n",
       " 'pay': 376,\n",
       " 'birth': 377,\n",
       " 'just': 378,\n",
       " 'skulls': 379,\n",
       " 'rogers': 380,\n",
       " 'rangers': 381,\n",
       " 'full': 382,\n",
       " 'lank': 383,\n",
       " 'shivery': 384,\n",
       " 'halfdrowned': 385,\n",
       " 'office': 386,\n",
       " 'illumine': 387,\n",
       " 'enkindle': 388,\n",
       " 'has': 389,\n",
       " 'changed': 390,\n",
       " 'thinks': 391,\n",
       " 'dark': 392,\n",
       " 'flooded': 393,\n",
       " 'daylight': 394,\n",
       " 'broke': 395,\n",
       " 'trance': 396,\n",
       " 'suspicious': 397,\n",
       " 'knowing': 398,\n",
       " 'way': 399,\n",
       " 'leads': 400,\n",
       " 'because': 401,\n",
       " 'wear': 402,\n",
       " 'athens': 403,\n",
       " 'deliverance': 404,\n",
       " 'gave': 405,\n",
       " 'behind': 406,\n",
       " 'headboard': 407,\n",
       " 'bed': 408,\n",
       " 'coat': 409,\n",
       " 'good': 410,\n",
       " 'seated': 411,\n",
       " 'otherwise': 412,\n",
       " 'fall': 413,\n",
       " 'heart': 414,\n",
       " 'wake': 415,\n",
       " 'sigh': 416,\n",
       " 'hes': 417,\n",
       " 'dropped': 418,\n",
       " 'child': 419,\n",
       " 'wed': 420,\n",
       " 'these': 421,\n",
       " 'years': 422,\n",
       " 'between': 423,\n",
       " 'ourselves': 424,\n",
       " 'difference': 425,\n",
       " 'turned': 426,\n",
       " 'repented': 427,\n",
       " 'coming': 428,\n",
       " 'get': 429,\n",
       " 'nails': 430,\n",
       " 'nail': 431,\n",
       " 'shut': 432,\n",
       " 'estelle': 433,\n",
       " 'castles': 434,\n",
       " 'used': 435,\n",
       " 'build': 436,\n",
       " 'air': 437,\n",
       " 'then': 438,\n",
       " 'ran': 439,\n",
       " 'shouted': 440,\n",
       " 'master': 441,\n",
       " 'grange': 442,\n",
       " 'talk': 443,\n",
       " 'does': 444,\n",
       " 'mind': 445,\n",
       " 'garden': 446,\n",
       " 'enchanted': 447,\n",
       " 'do': 448,\n",
       " 'shes': 449,\n",
       " 'done': 450,\n",
       " 'harm': 451,\n",
       " 'books': 452,\n",
       " 'thrown': 453,\n",
       " 'irreverently': 454,\n",
       " 'about': 455,\n",
       " 'guide': 456,\n",
       " 'aright': 457,\n",
       " 'expense': 458,\n",
       " 'half': 459,\n",
       " 'an': 460,\n",
       " 'ear': 461,\n",
       " 'pianos': 462,\n",
       " 'vigor': 463,\n",
       " 'your': 464,\n",
       " 'summer': 465,\n",
       " 'dwelling': 466,\n",
       " 'blushed': 467,\n",
       " 'bloomed': 468,\n",
       " 'whole': 469,\n",
       " 'mighty': 470,\n",
       " 'old': 471,\n",
       " 'home': 472,\n",
       " 'shatter': 473,\n",
       " 'inward': 474,\n",
       " 'unswept': 475,\n",
       " 'floors': 476,\n",
       " 'very': 477,\n",
       " 'last': 478,\n",
       " 'far': 479,\n",
       " 'down': 480,\n",
       " 'within': 481,\n",
       " 'dim': 482,\n",
       " 'west': 483,\n",
       " 'when': 484,\n",
       " 'someone': 485,\n",
       " 'doing': 486,\n",
       " 'ask': 487,\n",
       " 'joe': 488,\n",
       " 'dread': 489,\n",
       " 'ominous': 490,\n",
       " 'stain': 491,\n",
       " 'tar': 492,\n",
       " 'voices': 493,\n",
       " 'seem': 494,\n",
       " 'didst': 495,\n",
       " 'glide': 496,\n",
       " 'remained': 497,\n",
       " 'preyest': 498,\n",
       " 'thou': 499,\n",
       " 'thus': 500,\n",
       " 'upon': 501,\n",
       " 'poets': 502,\n",
       " 'wouldst': 503,\n",
       " 'leave': 504,\n",
       " 'wandering': 505,\n",
       " 'creaking': 506,\n",
       " 'feet': 507,\n",
       " 'our': 508,\n",
       " 'pretty': 509,\n",
       " 'things': 510,\n",
       " 'outdoors': 511,\n",
       " 'height': 512,\n",
       " 'adventure': 513,\n",
       " 'fancied': 514,\n",
       " 'looked': 515,\n",
       " 'six': 516,\n",
       " 'oclock': 517,\n",
       " 'rural': 518,\n",
       " 'letterbox': 519,\n",
       " 'lajway': 520,\n",
       " 'tamed': 521,\n",
       " 'primeval': 522,\n",
       " 'wood': 523,\n",
       " 'deem': 524,\n",
       " 'wise': 525,\n",
       " 'need': 526,\n",
       " 'object': 527,\n",
       " 'hid': 528,\n",
       " 'look': 529,\n",
       " 'o': 530,\n",
       " 'hyacinthine': 531,\n",
       " 'isle': 532,\n",
       " 'purple': 533,\n",
       " 'zante': 534,\n",
       " 'neck': 535,\n",
       " 'thought': 536,\n",
       " 'spare': 537,\n",
       " 'clothes': 538,\n",
       " 'bones': 539,\n",
       " 'skeleton': 540,\n",
       " 'enough': 541,\n",
       " 'stock': 542,\n",
       " 'village': 543,\n",
       " 'library': 544,\n",
       " 'grace': 545,\n",
       " 'beauty': 546,\n",
       " 'fanes': 547,\n",
       " 'babylonlike': 548,\n",
       " 'walls': 549,\n",
       " 'legitimately': 550,\n",
       " 'demand': 551,\n",
       " 'bad': 552,\n",
       " 'live': 553,\n",
       " 'blandishments': 554,\n",
       " 'defied': 555,\n",
       " 'put': 556,\n",
       " 'stardials': 557,\n",
       " 'pointed': 558,\n",
       " 'morn': 559,\n",
       " 'sparkling': 560,\n",
       " 'evermore': 561,\n",
       " 'nor': 562,\n",
       " 'ghoulhaunted': 563,\n",
       " 'woodland': 564,\n",
       " 'weir': 565,\n",
       " 'darkest': 566,\n",
       " 'evening': 567,\n",
       " 'thoughts': 568,\n",
       " 'palsied': 569,\n",
       " 'fell': 570,\n",
       " 'upturnd': 571,\n",
       " 'faces': 572,\n",
       " 'roses': 573,\n",
       " 'wonder': 574,\n",
       " 'makebelieve': 575,\n",
       " 'speel': 576,\n",
       " 'every': 577,\n",
       " 'single': 578,\n",
       " 'lizard': 579,\n",
       " 'ill': 580,\n",
       " 'find': 581,\n",
       " 'pacified': 582,\n",
       " 'psyche': 583,\n",
       " 'kissed': 584,\n",
       " 'room': 585,\n",
       " 'demon': 586,\n",
       " 'tempted': 587,\n",
       " 'davis': 588,\n",
       " 'graciously': 589,\n",
       " 'windbreak': 590,\n",
       " 'roof': 591,\n",
       " 'did': 592,\n",
       " 'float': 593,\n",
       " 'flow': 594,\n",
       " 'poetesss': 595,\n",
       " 'cottages': 596,\n",
       " 'row': 597,\n",
       " 'expanding': 598,\n",
       " 'happy': 599,\n",
       " 'flowers': 600,\n",
       " 'repining': 601,\n",
       " 'throats': 602,\n",
       " 'vacuum': 603,\n",
       " 'filmy': 604,\n",
       " 'turrettops': 605,\n",
       " 'clouds': 606,\n",
       " 'trailing': 607,\n",
       " 'moments': 608,\n",
       " 'misted': 609,\n",
       " 'same': 610,\n",
       " 'seize': 611,\n",
       " 'catscradle': 612,\n",
       " 'strings': 613,\n",
       " 'radiant': 614,\n",
       " 'palace': 615,\n",
       " 'reared': 616,\n",
       " 'head': 617,\n",
       " 'western': 618,\n",
       " 'couch': 619,\n",
       " 'thundercloud': 620,\n",
       " 'immemorial': 621,\n",
       " 'grandchildren': 622,\n",
       " 'remembering': 623,\n",
       " 'fold': 624,\n",
       " 'across': 625,\n",
       " 'pride': 626,\n",
       " 'ancestry': 627,\n",
       " 'yankees': 628,\n",
       " 'hate': 629,\n",
       " 'huh': 630,\n",
       " 'bathtub': 631,\n",
       " 'astartes': 632,\n",
       " 'bediamonded': 633,\n",
       " 'crescent': 634,\n",
       " 'smoothlaid': 635,\n",
       " 'thatch': 636,\n",
       " 'heavy': 637,\n",
       " 'dew': 638,\n",
       " 'feathers': 639,\n",
       " 'heat': 640,\n",
       " 'faster': 641,\n",
       " 'slower': 642,\n",
       " 'chanced': 643,\n",
       " 'sad': 644,\n",
       " 'silent': 645,\n",
       " 'watches': 646,\n",
       " 'hadnt': 647,\n",
       " 'long': 648,\n",
       " 'suspected': 649,\n",
       " 'lurid': 650,\n",
       " 'sea': 651,\n",
       " 'henceforth': 652,\n",
       " 'flowerenameled': 653,\n",
       " 'shore': 654,\n",
       " 'joy': 655,\n",
       " 'wo': 656,\n",
       " 'swift': 657,\n",
       " 'founts': 658,\n",
       " 'bliss': 659,\n",
       " 'hell': 660,\n",
       " 'confusion': 661,\n",
       " 'them': 662,\n",
       " 'aglitter': 663,\n",
       " 'road': 664,\n",
       " 'matter': 665,\n",
       " 'several': 666,\n",
       " 'miles': 667,\n",
       " 'state': 668,\n",
       " 'glory': 669,\n",
       " 'well': 670,\n",
       " 'befitting': 671,\n",
       " 'leg': 672,\n",
       " 'crutch': 673,\n",
       " 'beside': 674,\n",
       " 'track': 675,\n",
       " 'stay': 676,\n",
       " 'hed': 677,\n",
       " 'cant': 678,\n",
       " 'ever': 679,\n",
       " 'worse': 680,\n",
       " 'lift': 681,\n",
       " 'face': 682,\n",
       " 'soon': 683,\n",
       " 'satisfied': 684,\n",
       " 'reclining': 685,\n",
       " 'while': 686,\n",
       " 'roads': 687,\n",
       " 'diverged': 688,\n",
       " 'yellow': 689,\n",
       " 'else': 690,\n",
       " 'remoteness': 691,\n",
       " 'seen': 692,\n",
       " 'tears': 693,\n",
       " 'dry': 694,\n",
       " 'fervid': 695,\n",
       " 'flickering': 696,\n",
       " 'torch': 697,\n",
       " 'lit': 698,\n",
       " 'nausicaa': 699,\n",
       " 'unafraid': 700,\n",
       " 'doth': 701,\n",
       " 'listen': 702,\n",
       " 'red': 703,\n",
       " 'levin': 704,\n",
       " 'mistrusted': 705,\n",
       " 'none': 706,\n",
       " 'proud': 707,\n",
       " 'business': 708,\n",
       " 'firsts': 709,\n",
       " 'gnawing': 710,\n",
       " 'till': 711,\n",
       " 'whined': 712,\n",
       " 'fair': 713,\n",
       " 'fairest': 714,\n",
       " 'hole': 715,\n",
       " 'somewhere': 716,\n",
       " 'heel': 717,\n",
       " 'reach': 718,\n",
       " 'seriously': 719,\n",
       " 'bearings': 720,\n",
       " 'board': 721,\n",
       " 'laid': 722,\n",
       " 'walk': 723,\n",
       " 'dryshod': 724,\n",
       " 'concerned': 725,\n",
       " 'whom': 726,\n",
       " 'along': 727,\n",
       " 'shouting': 728,\n",
       " 'few': 729,\n",
       " 'people': 730,\n",
       " 'turn': 731,\n",
       " 'doll': 732,\n",
       " 'pasture': 733,\n",
       " 'rig': 734,\n",
       " 'despairs': 735,\n",
       " 'unhallowed': 736,\n",
       " 'hours': 737,\n",
       " 'atmosphere': 738,\n",
       " 'found': 739,\n",
       " 'gnawed': 740,\n",
       " 'four': 741,\n",
       " 'posts': 742,\n",
       " 'absence': 743,\n",
       " 'dawn': 744,\n",
       " 'goes': 745,\n",
       " 'ocean': 746,\n",
       " 'throbbing': 747,\n",
       " 'free': 748,\n",
       " 'hope': 749,\n",
       " 'utter': 750,\n",
       " 'spells': 751,\n",
       " 'broken': 752,\n",
       " 'oldbelievers': 753,\n",
       " 'talking': 754,\n",
       " 'marshall': 755,\n",
       " 'donkeys': 756,\n",
       " 'ears': 757,\n",
       " 'soul': 758,\n",
       " 'least': 759,\n",
       " 'solace': 760,\n",
       " 'hath': 761,\n",
       " 'shudder': 762,\n",
       " 'notes': 763,\n",
       " 't': 764,\n",
       " 'until': 765,\n",
       " 'id': 766,\n",
       " 'worn': 767,\n",
       " 'skin': 768,\n",
       " 'wanderers': 769,\n",
       " 'valley': 770,\n",
       " 'lavas': 771,\n",
       " 'restlessly': 772,\n",
       " 'roll': 773,\n",
       " 'guessed': 774,\n",
       " 'theyd': 775,\n",
       " 'wants': 776,\n",
       " 'hens': 777,\n",
       " 'best': 778,\n",
       " 'also': 779,\n",
       " 'great': 780,\n",
       " 'politician': 781,\n",
       " 'odd': 782,\n",
       " 'seasons': 783,\n",
       " 'truth': 784,\n",
       " 'gold': 785,\n",
       " 'buy': 786,\n",
       " 'lonely': 787,\n",
       " 'rose': 788,\n",
       " 'neednt': 789,\n",
       " 'going': 790,\n",
       " 'doesnt': 791,\n",
       " 'pallor': 792,\n",
       " 'strangely': 793,\n",
       " 'mistrust': 794,\n",
       " 'speak': 795,\n",
       " 'dialect': 796,\n",
       " 'voice': 797,\n",
       " 'sorrowfully': 798,\n",
       " 'trailed': 799,\n",
       " 'dust': 800,\n",
       " 'hoed': 801,\n",
       " 'yesterday': 802,\n",
       " 'fur': 803,\n",
       " 'trade': 804,\n",
       " 'supposed': 805,\n",
       " 'mad': 806,\n",
       " 'abode': 807,\n",
       " 'theres': 808,\n",
       " 'something': 809,\n",
       " 'keeping': 810,\n",
       " 'got': 811,\n",
       " 'settled': 812,\n",
       " 'wrong': 813,\n",
       " 'prove': 814,\n",
       " 'warriors': 815,\n",
       " 'unknown': 816,\n",
       " 'foe': 817,\n",
       " 'remaining': 818,\n",
       " 'aster': 819,\n",
       " 'flower': 820,\n",
       " 'chimney': 821,\n",
       " 'started': 822,\n",
       " 'above': 823,\n",
       " 'stove': 824,\n",
       " 'gushing': 825,\n",
       " 'strange': 826,\n",
       " 'forgive': 827,\n",
       " 'witch': 828,\n",
       " 'happened': 829,\n",
       " 'acquainted': 830,\n",
       " 'ghost': 831,\n",
       " 'amid': 832,\n",
       " 'entombing': 833,\n",
       " 'fingerbone': 834,\n",
       " 'knew': 835,\n",
       " 'place': 836,\n",
       " 'kinsman': 837,\n",
       " 'sill': 838,\n",
       " 'sybilic': 839,\n",
       " 'splendor': 840,\n",
       " 'beaming': 841,\n",
       " 'fix': 842,\n",
       " 'speaking': 843,\n",
       " 'bandmusic': 844,\n",
       " 'playing': 845,\n",
       " 'wreathed': 846,\n",
       " 'myrtle': 847,\n",
       " 'sword': 848,\n",
       " 'conceal': 849,\n",
       " 'month': 850,\n",
       " 'october': 851,\n",
       " 'bill': 852,\n",
       " 'family': 853,\n",
       " 'im': 854,\n",
       " 'member': 855,\n",
       " 'happier': 856,\n",
       " 'resemble': 857,\n",
       " 'ours': 858,\n",
       " 'ripples': 859,\n",
       " 'curl': 860,\n",
       " 'alas': 861,\n",
       " 'frozen': 862,\n",
       " 'lake': 863,\n",
       " 'hear': 864,\n",
       " 'news': 865,\n",
       " 'dreadful': 866,\n",
       " 'fool': 867,\n",
       " 'believe': 868,\n",
       " 'feather': 869,\n",
       " 'safely': 870,\n",
       " 'may': 871,\n",
       " 'trust': 872,\n",
       " 'gleaming': 873,\n",
       " 'groan': 874,\n",
       " 'mount': 875,\n",
       " 'yaanek': 876,\n",
       " 'among': 877,\n",
       " 'unearthed': 878,\n",
       " 'potatoes': 879,\n",
       " 'imbued': 880,\n",
       " 'acquaintance': 881,\n",
       " 'adventurously': 882,\n",
       " 'gnaw': 883,\n",
       " 'fences': 884,\n",
       " 'manages': 885,\n",
       " 'upper': 886,\n",
       " 'hand': 887,\n",
       " 'stopped': 888,\n",
       " 'unusual': 889,\n",
       " 'today': 890,\n",
       " 'always': 891,\n",
       " 'ye': 892,\n",
       " 'avengers': 893,\n",
       " 'libertys': 894,\n",
       " 'wrongs': 895,\n",
       " 'blotting': 896,\n",
       " 'utterly': 897,\n",
       " 'disturbed': 898,\n",
       " 'doubt': 899,\n",
       " 'might': 900,\n",
       " 'liked': 901,\n",
       " 'nine': 902,\n",
       " 'times': 903,\n",
       " 'removed': 904,\n",
       " 'correct': 905,\n",
       " 'err': 906,\n",
       " 'arthur': 907,\n",
       " 'amy': 908,\n",
       " 'myself': 909,\n",
       " 'wetelbowed': 910,\n",
       " 'wetkneed': 911,\n",
       " 'strung': 912,\n",
       " 'hair': 913,\n",
       " 'looks': 914,\n",
       " 'fabric': 915,\n",
       " 'tin': 916,\n",
       " 'cupboard': 917,\n",
       " 'shelf': 918,\n",
       " 'showed': 919,\n",
       " 'signs': 920,\n",
       " 'flickers': 921,\n",
       " 'timeeaten': 922,\n",
       " 'towers': 923,\n",
       " 'tremble': 924,\n",
       " 'loom': 925,\n",
       " 'cypress': 926,\n",
       " 'havent': 927,\n",
       " 'show': 928,\n",
       " 'remember': 929,\n",
       " 'souls': 930,\n",
       " 'asked': 931,\n",
       " 'off': 932,\n",
       " 'wild': 933,\n",
       " 'backs': 934,\n",
       " 'kiting': 935,\n",
       " 'lest': 936,\n",
       " 'truant': 937,\n",
       " 'pen': 938,\n",
       " 'falls': 939,\n",
       " 'powerless': 940,\n",
       " 'shivering': 941,\n",
       " 'earthly': 942,\n",
       " 'weather': 943,\n",
       " 'conquered': 944,\n",
       " 'scruples': 945,\n",
       " 'gloom': 946,\n",
       " 'rouse': 947,\n",
       " 'cosmic': 948,\n",
       " 'motes': 949,\n",
       " 'theirs': 950,\n",
       " 'interlock': 951,\n",
       " 'near': 952,\n",
       " 'paradise': 953,\n",
       " 'means': 954,\n",
       " 'seven': 955,\n",
       " 'caves': 956,\n",
       " 'came': 957,\n",
       " 'plumes': 958,\n",
       " 'wasps': 959,\n",
       " 'went': 960,\n",
       " 'missing': 961,\n",
       " 'bullets': 962,\n",
       " 'right': 963,\n",
       " 'past': 964,\n",
       " 'father': 965,\n",
       " 'neither': 966,\n",
       " 'judged': 967,\n",
       " 'crystal': 968,\n",
       " 'chill': 969,\n",
       " 'outer': 970,\n",
       " 'windowsill': 971,\n",
       " 'science': 972,\n",
       " 'true': 973,\n",
       " 'daughter': 974,\n",
       " 'themselves': 975,\n",
       " 'peckerfretted': 976,\n",
       " 'apple': 977,\n",
       " 'gives': 978,\n",
       " 'harness': 979,\n",
       " 'shake': 980,\n",
       " 'disappeared': 981,\n",
       " 'ended': 982,\n",
       " 'flung': 983,\n",
       " 'burned': 984,\n",
       " 'stake': 985,\n",
       " 'grass': 986,\n",
       " 'thrive': 987,\n",
       " 'johns': 988,\n",
       " 'god': 989,\n",
       " 'funereal': 990,\n",
       " 'mossy': 991,\n",
       " 'banks': 992,\n",
       " 'meandering': 993,\n",
       " 'paths': 994,\n",
       " 'crosslegged': 995,\n",
       " 'sweetest': 996,\n",
       " 'gods': 997,\n",
       " 'creatures': 998,\n",
       " 'shelfs': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2514"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data into integer format\n",
    "train_text_int = []\n",
    "test_text_int = []\n",
    "\n",
    "for text in train_text:\n",
    "  tokens = text.split()\n",
    "  line_as_int = [word2idx[token] for token in tokens]\n",
    "  train_text_int.append(line_as_int)\n",
    "\n",
    "for text in test_text:\n",
    "  tokens = text.split()\n",
    "  line_as_int = [word2idx.get(token, 0) for token in tokens]\n",
    "  test_text_int.append(line_as_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[143, 386, 45, 109, 387, 6, 388],\n",
       " [71, 389, 81, 390],\n",
       " [26, 391, 357, 392, 6, 357, 393, 132, 394],\n",
       " [26, 395, 276, 396, 70, 40, 347, 124, 397],\n",
       " [326, 398, 351, 399, 400, 63, 109, 399]]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_int[100:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize A and pi matrices - for both classes\n",
    "V = len(word2idx)\n",
    "\n",
    "A0 = np.ones((V, V))\n",
    "pi0 = np.ones(V)\n",
    "\n",
    "A1 = np.ones((V, V))\n",
    "pi1 = np.ones(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute counts for A and pi\n",
    "def compute_counts(text_as_int, A, pi):\n",
    "  for tokens in text_as_int:\n",
    "    last_idx = None\n",
    "    for idx in tokens:\n",
    "      if last_idx is None:\n",
    "        # it's the first word in a sentence\n",
    "        pi[idx] += 1\n",
    "      else:\n",
    "        # the last word exists, so count a transition\n",
    "        A[last_idx, idx] += 1\n",
    "\n",
    "      # update last idx\n",
    "      last_idx = idx\n",
    "\n",
    "\n",
    "compute_counts([t for t, y in zip(train_text_int, Ytrain) if y == 0], A0, pi0)\n",
    "compute_counts([t for t, y in zip(train_text_int, Ytrain) if y == 1], A1, pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize A and pi so they are valid probability matrices\n",
    "# convince yourself that this is equivalent to the formulas shown before\n",
    "A0 /= A0.sum(axis=1, keepdims=True)\n",
    "pi0 /= pi0.sum()\n",
    "\n",
    "A1 /= A1.sum(axis=1, keepdims=True)\n",
    "pi1 /= pi1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log A and pi since we don't need the actual probs\n",
    "logA0 = np.log(A0)\n",
    "logpi0 = np.log(pi0)\n",
    "\n",
    "logA1 = np.log(A1)\n",
    "logpi1 = np.log(pi1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.34365325077399383, 0.6563467492260062)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute priors\n",
    "count0 = sum(y == 0 for y in Ytrain)\n",
    "count1 = sum(y == 1 for y in Ytrain)\n",
    "total = len(Ytrain)\n",
    "p0 = count0 / total\n",
    "p1 = count1 / total\n",
    "logp0 = np.log(p0)\n",
    "logp1 = np.log(p1)\n",
    "p0, p1\n",
    "\n",
    "# P0 is about 33 percent and P one is about sixty six percent because of this, it wouldn't make sense to use the maximum likelihood method.\n",
    "# Instead, we should look at the posterior, which corresponds to the map method.\n",
    "# Note also that because the classes are slightly imbalanced, we may want to use a metric other than\n",
    "# the accuracy to evaluate a classifier.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a classifier\n",
    "class Classifier:\n",
    "  def __init__(self, logAs, logpis, logpriors):\n",
    "    self.logAs = logAs\n",
    "    self.logpis = logpis\n",
    "    self.logpriors = logpriors\n",
    "    self.K = len(logpriors) # number of classes\n",
    "\n",
    "  def _compute_log_likelihood(self, input_, class_):\n",
    "    logA = self.logAs[class_]\n",
    "    logpi = self.logpis[class_]\n",
    "\n",
    "    last_idx = None\n",
    "    logprob = 0\n",
    "    for idx in input_:\n",
    "      if last_idx is None:\n",
    "        # it's the first token\n",
    "        logprob += logpi[idx]\n",
    "      else:\n",
    "        logprob += logA[last_idx, idx]\n",
    "      \n",
    "      # update last_idx\n",
    "      last_idx = idx\n",
    "    \n",
    "    return logprob\n",
    "  \n",
    "  def predict(self, inputs):\n",
    "    predictions = np.zeros(len(inputs))\n",
    "    for i, input_ in enumerate(inputs):\n",
    "      posteriors = [self._compute_log_likelihood(input_, c) + self.logpriors[c] \\\n",
    "             for c in range(self.K)]\n",
    "      pred = np.argmax(posteriors)\n",
    "      predictions[i] = pred\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each array must be in order since classes are assumed to index these lists\n",
    "clf = Classifier([logA0, logA1], [logpi0, logpi1], [logp0, logp1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 0.9962848297213622\n"
     ]
    }
   ],
   "source": [
    "Ptrain = clf.predict(train_text_int)\n",
    "print(f\"Train acc: {np.mean(Ptrain == Ytrain)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acc: 0.8460111317254174\n"
     ]
    }
   ],
   "source": [
    "Ptest = clf.predict(test_text_int)\n",
    "print(f\"Test acc: {np.mean(Ptest == Ytest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 549,    6],\n",
       "       [   0, 1060]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(Ytrain, Ptrain)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 93,  70],\n",
       "       [ 13, 363]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_test = confusion_matrix(Ytest, Ptest)\n",
    "cm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9971777986829726"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Ytrain, Ptrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8974042027194068"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(Ytest, Ptest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
